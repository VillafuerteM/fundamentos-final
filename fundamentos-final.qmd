---
title: "Final-2023" 
author: 
  - "Mariano Villafuerte - 156057" 
  - "Mario Medina - 156940" 
editor: visual 
output: pdf_document 
css: |
    body {
        line-height: 1.5
    }
format:  
  pdf:     
    include-in-header:       
      text: '\addtokomafont{disposition}{\rmfamily} ' 
---

```{r librerias_lectura, include=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(patchwork)
library(kableExtra)
library(knitr)
library(ggpubr)
library(tidyr)
library(fivethirtyeight)
library(nullabor)
library(actuar)
library(foreign)
library(ggrepel)
library(cmdstanr)
library(posterior)
library(tidyverse)
# wd <- "C:/Users/mario/OneDrive/Documentos/fundamentos-final"
# setwd(wd)

set.seed(156057)
options(scipen=999)
```

## 1. Pruebas de hipótesis

**1.1** De acuerdo a una encuesta en EUA, 26% de los residentes adultos de Illinois han terminado la preparatoria. Un investigador sospecha que este porcentaje es menor en un condado particular del estado. Obtiene una muestra aleatoria de dicho condado y encuentra que 69 de 310 personas en la muestra han completado la preparatoria. Estos resultados soportan su hipótesis?

**Respuesta:**

Podemos tomar 2 enfoques, a continuación explicamos el porqué

-   **Prueba con estadístico Z**: dado que hablamos de proporciones sabemos cuál es el error estándar de una proporción, podremos calcular el estadístico Z, dada la naturaleza de la prueba también puede definirse como una prueba de Wald

-   **Enfoque bayesiano:** el 26% nos ayuda a definir una a priori y con los datos podemos generar una posterior. No es un cálculo de prueba de hipótesis tal cual pero podemos obtener intervalos de credibilidad que nos ayuden a determinar si realmente es significativamente menor.

Empezamos con la **prueba del estadístico Z**, nuestra prueba de hipótesis la podemos definir como (1 cola)

$$
 \begin{aligned}&H_{0}: \hat{\theta}=0.26 \\&H_{1}: \hat{\theta}<0.26\end{aligned}
$$

Y el estadístico se vería de la siguiente forma. Sabemos que $\hat{\theta}=\frac{69}{310}$

$$
Z = \frac{\hat{\theta}-0.26}{\sqrt{\frac{0.26(1-0.26)}{310}}} = -1.502016
$$

El valor-p considerando que es de una cola sería, en específico la izquierda

$$
p-value=P(Z<z)
$$

el cálculo se ve de la siguiente manera.

```{r calc_p_value}
numerador = (69/310)-0.26
denominador = sqrt((0.26*0.74)/310)
p_value <- pnorm(numerador/denominador)
```

```{r print_p_value, echo=FALSE}
print(paste0("El valor p asociado a esta prueba es: ", round(p_value,2)))
```

**La conclusión es que no es significativo al 95% de confianza**. Debido a que es mayor al valor crítico de 5%, por lo que no hay suficiente evidencia para rechazar la hipótesis nula.

**Enfoque bayesiano**: El problema trata de la estimación de una proporción, llamémosle $\theta$ donde $\theta$ es la proporción de adultos que terminaron la preparatoria en el condado específico de Illinois. Podemos asumir una a priori $P(\theta)$ que siga la información inicial que nos dice que ese porcentaje dentro de Illinois es de aproximadamente $26\%$, entonces usaremos una **Beta** que después de prueba y error tiene los parámetros $(4,11)$ que tiene de media $0.26$ sin estar muy concentrada.

```{r sim_dist_inicial, warning = FALSE}
set.seed(156057)
sim_inicial <- tibble(theta = stats::rbeta(10000,4,11))
```

```{r grafica_dist_inicial, warning = FALSE}
#| fig.height = 2.7,
#| warning=FALSE,
#| echo=FALSE, 
#| fig.cap = "Distribución a priori: Beta (4,11)"

ggplot(sim_inicial) + 
  geom_histogram(aes(x = theta, 
                     y = ..density..), 
                 bins = 15, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = 0.26, 
             color = "red",
             linetype='dashed') +
  labs(title = "Distribución Inicial", 
       subtitle = "Beta(4,11)") + 
  xlab("Theta") + 
  ylab("Densidad") + 
  ggpubr::theme_pubclean(base_size = 12)
```

{{< pagebreak >}}

Los datos del condado nos dicen que de 310 individuos únicamente tenemos 69 con preparatoria concluida (éxitos) entonces nuestra posterior queda de la siguiente manera

$$
P(\theta|X) \propto P(X|\theta)P(\theta) \\
P(\theta|X) \propto \theta^{69+3}(1-\theta)^{241+10} \\
P(\theta|X) \propto \theta^{72}(1-\theta)^{251}
$$

Obtenemos los siguientes histogramas.

```{r posterior}
set.seed(156057)
sim_inicial <- sim_inicial %>% mutate(dist = "inicial")
sim_posterior <- tibble(theta = rbeta(10000, 73, 252)) %>% 
  mutate(dist = "posterior")

sims <- bind_rows(sim_inicial, sim_posterior)
```

```{r graph_post_ini, warning = FALSE}
#| echo=FALSE,
#| fig.cap="Inicial vs. Posterior",
#| fig.height=4

ggplot(sims, aes(x = theta, fill = dist)) +
  geom_histogram(aes(x = theta), 
                 bins = 30,
                 alpha = 0.5, 
                 position = "identity") +
  geom_vline(xintercept = 0.26, 
             color = "red",
             linetype='dashed') +
  geom_vline(xintercept = 0.2246, 
             color = "blue",
             linetype='dashed') +
  labs(title = "Distribución Inicial y Posterior",
       subtitle = "Beta(4,11) vs. Beta(73,252)",
       fill='Distribución') + 
  xlab("theta") + 
  ylab("Densidad") + 
  theme_pubclean(base_size = 12)
```

{{< pagebreak >}}

**Un estimador puntual** es la media de la distribuciones, que al ser una Beta se obtiene como $\frac{a}{a+b}$

-   Dist. Inicial: $\frac{4}{4+11} = 0.267$

-   Dist. Posterior: $\frac{73}{73+252} = 0.2246$

-   Máxima verosimilitud: $\frac{69}{310} = 0.2226$

Asímismo podemos obtener intervalos de credibilidad fácilmente debido a nuestra distribución "conocida"

```{r calc_intervalo, warning = FALSE}
set.seed(156057)
inferior <- round(qbeta(0.025, shape1 = 73, shape2 = 252),2)
superior <- round(qbeta(0.975, shape1 = 73, shape2 = 252),2)
```

```{r imprime_intervalo, echo=FALSE}
tibble(Inferior=inferior,
       Superior=superior) %>%
  kable(format='latex', 
        booktabs=T,
        caption = 'Intervalo dist. posterior') %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

Dado la información anterior el **intervalo de confianza al 95% de la posterior sí incluye el valor del 26%. Por lo que todavía no es del todo "aceptable"** que la proporción del condado sea significativamente menor al del estado de Illinois La conclusión de este enfoque es el mismo que en el primero.

{{< pagebreak >}}

**1.2** Mendel criaba chícharos de semillas lisas amarillas y de semillas corrugadas verdes. Éstas daban lugar a 4 tipos de descendientes: amarrillas lisas, amarillas corrugadas, verdes lisas y verdes corrugadas. El número de cada una es multinomial con parámetro $p=(p_1, p_2, p_3, p_4)$ . De acuerdo a su teoría de herencia este vector de probabilidades es:

$$
p=(9/16,3/16,3/16,1/16)
$$

A lo largo de $n=556$ experimentos observó $x=(315,101,108,32)$. Utiliza la prueba de cociente de verosimilitudes para probar $H_0:p=p_0$ contra $H_0:p\ne p_0$.

**Respuesta**

La distribución multinomial para este problema la definimos de la siguiente manera

$$
p(x_1,x_2,x_3,x_4|p_1,p_2,p_3,p_4) = \frac{n!}{x_1!x_2!x_3!x_4!}p_1^{x_1}p_2^{x_2}p_3^{x_3}p_4^{x_4}
$$

La primera parte será constante al momento de sacar la log-verosimilitud, por lo que la parte de interes nos queda de la siguiente forma.

$$
l(p_1,p_2,p_3,p_4) = \sum_{i=1}^{4}x_{i}log(p_{i})
$$

También sabemos que el estimador de máxima verosimilitud para cada $p_{i}$ es $\frac{x_{i}}{n}$

Para la prueba de hipótesis de cociente de verosimilitud necesitamos calcular la log-verosimilitud bajo la hipotesis nula $p$ y la log verosimilitud utilizando los estimadores de máxima verosimilitud. Lo haremos bajo simulación

Definimos

$$
\lambda = 2[l(\hat{p})-l(p_0)]
$$

```{r log_verosim, warning = FALSE}
set.seed(156057)
experimentos <- 556
observaciones <- c(315, 101, 108, 32)
prob_nulas <- c(9/16,3/16,3/16,1/16)
simul_nula <- rmultinom(15000, experimentos, prob_nulas)

lambda <- function(n, x, p = prob_nulas){
  # Estimadores MV
  p1_mv <- x[1]/n
  p2_mv <- x[2]/n
  p3_mv <- x[3]/n
  p4_mv <- x[4]/n
  # log verosimilitud bajo mv
  log_p_mv <- x[1]*log(p1_mv)+x[2]*log(p2_mv)+x[3]*log(p3_mv)+x[4]*log(p4_mv)
  # log verosimilitud bajo nula
  log_p_nula <- x[1]*log(p[1])+x[2]*log(p[2])+x[3]*log(p[3])+x[4]*log(p[4])
  lambda <- 2*(log_p_mv - log_p_nula)
  lambda
}

lambda_obs <- lambda(experimentos, observaciones, prob_nulas)


new_df <- data.frame(simul_nula)
sims_tbl <- data.frame(sim_x = I(as.list(new_df))) 
sims_tbl <- sims_tbl %>% 
  mutate(lambda = map_dbl(sim_x,
                          ~lambda(experimentos,
                                  .x,
                                  prob_nulas)))
```

```{r graph_sims_tbl, echo=FALSE, fig.cap = "Distribución Lambda"}
ggplot(sims_tbl, aes(x = lambda)) + 
  geom_histogram(aes(x = lambda, 
                     y = ..density..), 
                 bins = 30, 
                 fill ="cyan4", 
                 alpha=0.4) +
  geom_vline(xintercept = lambda_obs, 
             color = "red", 
             linetype='dashed') +  
  labs(title = "Distribución Lambda", 
       subtitle = "Cociente de verosimilitud") + 
  xlab("Lambda") + 
  ylab("Densidad") + 
  ggpubr::theme_pubclean(base_size = 12)
```

Calculamos nuestro valor p.

```{r valor_p_alpha, warning = FALSE}
valor_p <- mean(sims_tbl$lambda >= lambda_obs)
```

```{r print_pv_alpha, echo=FALSE}
print(paste0("El valor p asociado a esta prueba es: ", 
             round(valor_p,2)))
```

Por lo que **no encontramos evidencia encontra de la hipótesis nula**. Hace sentido ya que desde la Lambda observada el valor es cercano a 0, por lo que la nula tiene bastante verosimilitud respecto a lo que los datos indican.

{{< pagebreak >}}

**1.3**. Sean $X_1, …X_n \sim Poisson(\lambda)$,

\* Sea $\lambda_0>0$. ¿Cuál es la prueba Wald para $H_0: \lambda = \lambda_0, H_1: \lambda \neq \lambda_0$?

\* Si $\lambda_0=1$, $n=20$ y $\alpha = 0.05$. Simula $X_1, …X_n \sim Poisson(\lambda_0)$ y realiza la prueba Wald, repite 1000 veces y registra el porcentaje de veces que rechazas $H_0$, qué tan cerca te queda el error del tipo 1 de $0.05$?

**Respuesta**

Para el primer inciso, hemos visto varias veces que el mejor estimador para $\lambda$ de una Poisson será la media. Asimismo hemos visto resultados asintóticos donde la media tiene normalidad asintótica dicho esto podemos declarar que

$$
W = \frac{\hat{\lambda} - \lambda}{\hat{ee}} \sim N(0,1)
$$

Y el **valor-p** asociado para la hipótesis nula de $H_0: \lambda = \lambda_0, H_1: \lambda \neq \lambda_0$ será

$$
valor-p \approx P(|Z| > |w|) = 2(1-\Phi(|w|))
$$

Ahora si asumimos que $\lambda_0=1$, $n=20$ y $\alpha = 0.05$. Podemos simular los datos de la siguiente manera. Un resultado importante es que como $\lambda$ es estimado con la media, el $\hat{ee}$ puede ser calculado como el error estándar de la media con $\frac{s}{\sqrt{n}}$

```{r wald, warning = FALSE}
set.seed(156057)
n <- 20
lambda0 <- 1
datos_wald <- rpois(n, lambda0)
p_values <- c()
for (i in 1:1000) {
  datos_wald <- rpois(n, lambda0)
  w_test <- (mean(datos_wald)-lambda0)/(sd(datos_wald)/sqrt(n))
  p_values[i] <- 2 * (1 - pnorm(abs(w_test)))
}
resumen_wald <- data.frame(
  p_val = p_values
)
resume_wald <- resumen_wald %>%
  dplyr::mutate(rechazo = ifelse(p_val<0.05, 1,0),
                distancia = abs(0.05-p_val), 
                point = seq(1,1000,1))
```

**Rechazo el 7% de las veces**. El ***Error del tipo I*** es la probabilidad de rechazar hipótesis nula de $H_{0}$ cuando es cierta, es decir que únicamente debemos calcular la distancia de aquellas simulaciones donde rechazamos

```{r tab_prop_wald, cho=FALSE}
resume_wald %>% 
  group_by(Rechazo=rechazo) %>% 
  summarise(Conteo=n(), Proporción =Conteo/1000) %>%
   kable(format='latex', 
        booktabs=T,
        caption = 'Proporción de rechazos de H0 con 1000 simulaciones') %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

```{r graph_rech_wald}
#| fig.cap = "Distancia entre el error del tipo I y 5%", 
#| warning=FALSE,
#| echo=FALSE

ggplot(resume_wald %>% filter(rechazo == 1),
       aes(x = point, 
           xend = point, 
           y = 0, 
           yend = distancia)) +
  geom_segment(size = 1, 
           color = 'red3') +
  labs(title = "Distancia al punto crítico",
       x = "Estimación",
       y = "distancia a 0.05",
       caption="*Se muestran solo los Rechazos de H0") +
  ggpubr::theme_pubclean(base_size = 12)
```

{{< pagebreak >}}

## 2. Relación entre bootstrap e inferencia bayesiana

Consideremos el caso en que tenemos una única observación $x$ proveniente de una distribución normal

$$
x \sim N(\theta, 1)
$$

Supongamos ahora que elegimos una distribución inicial Normal.

$$
\theta \sim N(0, \tau)
$$

dando lugar a la distribución posterior (como vimos en la tarea)

$$
\theta|x \sim N\bigg(\frac{x}{1 + 1/\tau}, \frac{1}{1+1/\tau}\bigg)
$$

Ahora, entre mayor $\tau$, más se concentra la posterior en el estimador de máxima verosimilitud $\hat{\theta}=x$. En el límite, cuando $\tau \to \infty$ obtenemos una inicial no-informativa (constante) y la distribución posterior

$$
\theta|x \sim N(x,1)
$$

Esta posterior coincide con la distribución de bootstrap paramétrico en que generamos valores $x^*$ de $N(x,1)$, donde $x$ es el estimador de máxima verosimilitud. Lo anterior se cumple debido a que utilizamos un ejemplo Normal pero también se cumple proximadamente en otros casos, lo que conlleva a una correspondencia entre el bootstrap paramétrico y la inferencia bayesiana. En este caso, la distribución bootstrap representa (aproximadamente) una distribución posterior no-informartiva del parámetro de interés. Mediante la perturbación en los datos el bootstrap aproxima el efecto bayesiano de perturbar los parámetros con la ventaja de ser más simple de implementar (en muchos casos).

-   Los detalles se pueden leer en \_The Elements of Statistical Learning\_ de Hastie y Tibshirani.

Comparemos los métodos en otro problema con el fin de apreciar la similitud en los procedimientos:

Supongamos $x_1,…,x_n \sim N(0, \sigma^2)$, es decir, los datos provienen de una distribución con media cero y varianza desconocida.

En los puntos 2.1 y 2.2 buscamos hacer inferencia del parámetro $\sigma^2$.

{{< pagebreak >}}

**2.1 Bootstrap paramétrico.**

-   Escribe la función de log-verosimilitud y calcula el estimador de máxima verosimilitud para $\sigma^2$. Supongamos que observamos los datos \`x\` (en la carpeta datos), ¿Cuál es tu estimación de la varianza?

**Respuesta:** Sabemos que $\mu=0$, entonces nos quedamos con la parte de la distribución que considera el término de $\sigma^2$. Tenemos 150 datos obtenidos del archivo *x.RData*

```{r lectura_x, warning = FALSE, include=FALSE}
#load(paste0("C:/Users/mario/OneDrive/Documentos/fundamentos-final/data/x.RData"))

load("data/x.RData")
```

$$
\begin{aligned}&& f(x|\mu,\sigma^2)&=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\&& f(x|0,\sigma^2)&=\frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{\sigma^2}}e^{-\frac{x^2}{2\sigma^2}} \\&& L(0,\sigma^2|x)&=\prod^{n}_{i=1} \frac{1}{\sqrt{2\pi}}(\sigma^2)^{\frac{-1}{2}}e^{-\frac{x_{i}^2}{2\sigma^2}} \propto (\sigma^2)^{\frac{-n}{2}}e^{-\frac{\sum^n x_{i}^2}{2\sigma^2}}\\&& l(0,\sigma^2|x) &= \frac{-n}{2}log(\sigma^2)-\frac{\sum^n x_{i}^2}{2}(\sigma^2)^{-1}\end{aligned}
$$

Tenemos $n=150$ y $\sum^{150}x^2 = 19693.64$ podemos hacerlo de forma manual y calcular la derivada e igualar a 0.

$$
\frac{\partial l}{\partial \sigma^2} = \frac{-150}{2}\frac{1}{\sigma^2} + \frac{19693.64}{2}\frac{1}{(\sigma^2)^2} =0 
$$

Se puede resolver asumiendo $x = \frac{1}{\sigma^2}$ y resolvemos por la "chicharronera"

```{r preg_2_1, warning = FALSE}
set.seed(156057)
# Coefficients
a <- 9846.821
b <- -75
c <- 0

# Quadratic formula
discriminant <- b^2 - 4 * a * c
x1 <- (-b + sqrt(discriminant)) / (2 * a)
x2 <- (-b - sqrt(discriminant)) / (2 * a)

# Reciprocal to get sigma^2
sigma_squared_1 <- 1 / x1
sigma_squared_2 <- 1 / x2
```

Lo que nos da un valor $\sigma^2_{mv} = 131.291$ . **Podemos verlo graficamente y replicarlo con métodos de optimización numérica**

```{r optim_sol, warning=FALSE}
set.seed(156057)
log_p <- function(pars){
    (-150/2)*log(pars[1]) - (19693.64/2)*((1)/pars[1])
}

solucion <- optim(c(0.5), log_p, 
                  control = list(fnscale = -1, maxit = 10000), 
                  method = "Nelder-Mead")
```

```{r print_converg, echo=FALSE}
print(paste0("Comprobamos convergencia: ",solucion$convergence))
```

```{r table_estimador, echo=FALSE}
est_mv <- tibble(parametro = c("Varianza"), 
                 estimador = solucion$par) %>% 
  column_to_rownames(var = "parametro")
```

```{r print_estimador, echo=FALSE}
est_mv %>% kable(format='latex', 
        booktabs=T) %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

Graficamos:

```{r datos_graph}
dat_verosim <- tibble(x = seq(5,300, 0.01)) %>% 
  mutate(log_prob = map_dbl(x, log_p))
```

```{r graph_datos_verosim}
#| warning = FALSE,
#| echo=FALSE,
#| fig.cap = "Optimización varianza" ,
#| fig.height=3

ggplot(dat_verosim, aes(x = x, y = log_prob)) + 
  geom_line() +
  geom_vline(xintercept = 131.65, 
             color = "red", 
             linetype='dashed') +
  labs(title = "Optimización") + 
  xlab("Varianza (sigma^2)") + 
  ylab("Log verosimilitud") + 
  theme_pubclean(base_size = 12)
```

-   Aproxima el error estándar de la estimación usando *bootstrap paramétrico* y realiza un histograma de las replicaciones bootstrap.

**Respuesta:** Creamos nuestro flujo de generador de muestra (utilizando el parámetro de máxima verosimilitud), cálculamos la log-verosimilitud y optimizamos

```{r bootstrap_param}
#| warning = FALSE, 
#| fig.cap = "Histograma replicaciones bootstrap"
set.seed(156057)

est_mle <- 131.65
n <- 150

rep_boot <- function(rep, log_p, n, est_mle){
  muestra_bootstrap <- rnorm(n, 0, sqrt(est_mle))
  
  log_p <- function(pars){
    (-n/2)*log(pars[1]) - (sum(muestra_bootstrap^2)/2)*((1)/pars[1])
  }
  
  solucion <- optim(c(0.5), log_p, 
                  control = list(fnscale = -1, maxit = 10000), 
                  method = "Nelder-Mead")
  try(if(solucion$convergence != 0) stop("No se alcanzó convergencia."))
  
  tibble(parametro = c("varianza"), estimador_boot = solucion$par) 
}

reps_boot <- map_dfr(1:15000, 
                     ~ rep_boot(.x, 
                                log_p, 
                                n = length(x),
                                est_mle), 
                     rep = ".id") 
```

```{r graph_boot_param}
#| echo=FALSE

ggplot(reps_boot, 
       aes(x = estimador_boot)) +
  geom_histogram(aes(x = estimador_boot, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "cyan4",
                 alpha=0.5) + 
  geom_vline(xintercept = est_mle, 
             color = "red", 
             linetype = "dashed") +
  labs(title = "Replicaciones bootstrap", 
       subtitle = "MLE: Varianza") + 
  xlab("Varianza (Sigma^2)") + 
  ylab("Densidad") + 
  ggpubr::theme_pubclean(base_size = 12)
```

Ahora podemos **calcular el error estándar de nuestra estimación**

```{r calc_err_est, warning = FALSE}
set.seed(156057)
error_est <- reps_boot %>% 
  group_by(parametro) %>% 
  summarise(ee_boot = sd(estimador_boot)) 
```

```{r print_err_est, echo=FALSE}
error_est %>% kable(format='latex', 
        booktabs=T) %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

Resumiendo. Nuestro $\sigma^2_{MLE} = 131.65$ y su $\hat{ee} = 15.34$

{{< pagebreak >}}

**2.2 Análisis bayesiano**

-   Continuamos con el problema de hacer inferencia de $\sigma^2$. Comienza especificando una inicial Gamma Inversa, justifica tu elección de los parámetros de la distribución inicial y grafica la función de densidad.

**Respuesta:** Empezamos definiendo una Gamma Inversa, **los parámetros al no tener mayor contexto del problema serán de un valor bajo mostrando que es una a priori con poca información. Asimismo buscando aprovechar las colas pesadas de la distribución ya que no tenemos certeza de la cantidad de varianza del problema** e.g $\alpha=0.05, \beta =2$

$$
f(\sigma^2) :\frac{\beta^\alpha}{\Gamma({\alpha})}*\frac{1}{(\sigma^2)^{\alpha+1}}*e^{\frac{\beta}{\sigma^2}}
$$

```{r dist_gamm_inv}
#| warning = FALSE,
#| fig.cap = "Distribución de inversa gamma"

set.seed(156057)

alpha <- 0.05
beta <- 2

# generamos distintos valores de sigma
sigma2_values <- seq(0.01, 150, by = 0.01)

# Calc densidad con inverse-gamma
density_values <- actuar::dinvgamma(sigma2_values, shape = alpha, rate = beta)

# data frame para graficar
df_sigma <- data.frame(sigma2 = sigma2_values, density = density_values)
```

```{r graph_gamma_inv}
#| echo=FALSE

ggplot(df_sigma, aes(x = sigma2, y = density)) +
  geom_line() +
  labs(title = "Función de densidad para la gamma inversa",
       subtitle = "InvGamma(0.05,2)",
       x = expression(sigma^2),
       y = "Densidad") +
  ggpubr::theme_pubclean(base_size = 12)
```

{{< pagebreak >}}

-   Calcula analíticamente la distribución posterior.

**Respuesta**: Sabemos que la posterior es el producto de los núcleos de la verosimilitud y de la apriori por lo que tenemos lo siguiente.

-   Conocemos "n" y la suma de $x^2$

-   Conocemos $\alpha$, $\beta$

$$
\begin{aligned}&& P(\sigma^2|x) &= P(x|\sigma^2)P(\sigma^2) \\&& P(\sigma^2|x) &\propto \left((\sigma^2)^{\frac{-n}{2}}e^{-\frac{\sum^n x_{i}^2}{2\sigma^2}}\right)\left((\sigma^2)^{-(\alpha+1)}e^{\frac{\beta}{\sigma^2}}\right) \\&& P(\sigma^2|x) &\propto (\sigma^2)^{-76.05}e^{\frac{9848.82}{\sigma^2}} \\&& P(\sigma^2|x) &\sim InvGamma(75.05,9848.82)\end{aligned}
$$

{{< pagebreak >}}

-   Realiza un histograma de simulaciones de la distribución posterior y calcula el error estándar de la distribución.

**Respuesta:**

```{r graph_a_b}
#| warning = FALSE,
#| fig.cap = "Comparativo Bayesiana vs. MLE"

set.seed(156057)
alpha_post <- 75.05
beta_post <- 9848.82

post_samples <- 1 / rgamma(15000, 
                           shape = alpha_post, 
                           rate = beta_post)

df_posterior <- data.frame(post_samples)
```

```{r}
#| echo=FALSE,
#| warning=FALSE
a <- ggplot(df_posterior, aes(x = post_samples)) +
  geom_histogram(aes(x = post_samples, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = (9848.82/74.05), 
             color = "red", 
             linetype = "dashed") +
  annotate("text", x = (9848.82/74.05), 
           y = Inf, 
           label = "E[sigma^2]: 133.00", 
           vjust = 1, 
           hjust = 0.5, 
           colour = "red3")+
  labs(title = "Simulaciones de posterior", 
       subtitle = "InvGamma(75.05,9848.82)") + 
  xlab("Varianza (Sigma^2)") + 
  ylab("Densidad") + 
  xlim(80,250)+
  ggpubr::theme_pubclean(base_size = 8)

b <- ggplot(reps_boot, aes(x = estimador_boot)) +
  geom_histogram(aes(x = estimador_boot, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = est_mle, 
             color = "red", 
             linetype = "dashed") +
  annotate("text", 
           x = est_mle, 
           y = Inf, 
           label = "MLE: 131.65", 
           vjust = 1, 
           hjust = 0.5,
           colour = "red3")+
  labs(title = "Replicaciones bootstrap", 
       subtitle = "MLE: Varianza") + 
  xlab("Varianza (Sigma^2)") + 
  ylab("Densidad") + 
  xlim(80,250)+
  ggpubr::theme_pubclean(base_size = 8)

a+b
```

Calculamos el error estándar

```{r ee_bayes, warning = FALSE, echo=FALSE}
set.seed(156057)
error_est_bayes <- df_posterior %>% 
  dplyr::mutate(parametro = "varianza") %>%
  dplyr::group_by(parametro) %>% 
  summarise(ee_bayes = sd(post_samples)) 
```

```{r print_ee_bayes}
#| echo=FALSE,
#| message=FALSE

error_est_bayes %>% 
  left_join(error_est) %>% 
  kable(format='latex', 
        booktabs=T) %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

{{< pagebreak >}}

-   ¿Cómo se comparan tus resultados con los de bootstrap paramétrico?

**Respuesta:** En la gráfica de arriba como en la tabla viene el comparativo de los estimadores. Ponemos de nuevo el resumen

-   *Bayesiana*:

    Calculamos el valor esperado: $E[\sigma^2] = \frac{\beta}{\alpha-1}=133.00$

-   *Bootstrap paramétrico*:

    Calculamos el estimador por medio de máxima verosimilitud (i.e derivando igualando a 0) $\sigma^2_{MV} = 131.65$

Y los errores estándar obtenido por medio de simulaciones.

-   *Bayesiana*:

    Distribución posterior $InvGamma(75.05,9848.82)$ : $\hat{ee}=15.459$

-   *Bootstrap paramétrico*:

    Distribución $Normal(0,\sigma^2_{MV})$ : $\hat{ee}=15.34$

$\Longrightarrow$ Corroboramos la correspondencia

{{< pagebreak >}}

**2.3** Supongamos que ahora buscamos hacer **inferencia del parámetro** $\tau=log(\sigma)$, ¿cuál es el estimador de máxima verosimilitud?

-   Utiliza bootstrap paramétrico para generar un intervalo de confianza del 95% para el parámetro $\tau$ y realiza un histograma de las replicaciones bootstrap.

**Respuesta:** Podemos argumentar al tratarse de una transformación logarítmica bien definida (sobre valores estricatamente positivos) que por la propiedad de **Equivarianza de MLE** que...

$$
\hat{\tau} = g(\hat{\sigma^2}) = log(\sqrt{131.65}) = 2.44
$$

será el **MLE** de $\tau$

```{r boot_tau_2_3}
#| warning = FALSE
reps_boot <- 
  reps_boot %>% dplyr::mutate(tau_boot = log(sqrt(estimador_boot)))
```

```{r graph_2_3_tau_boot}
#| warning = FALSE, 
#| fig.cap = "Histograma bootstrap: Tau",
#| echo=FALSE

ggplot(reps_boot, aes(x = tau_boot)) +
  geom_histogram(aes(x = tau_boot, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = 2.44, 
             color = "red", 
             linetype = "dashed") +
  labs(title = "Replicaciones bootstrap", 
       subtitle = "MLE: Tau") + 
  xlab("Tau") + 
  ylab("Densidad") + 
  ggpubr::theme_pubclean(base_size = 12)
```

Podemos utilizar **intervalos de cuantiles para reportar un intervalo al 95%**

```{r calc_intervalo_2.3, warning = FALSE}
quantil_95_izq <- quantile(reps_boot$tau_boot,.025)
quantil_95_der <- quantile(reps_boot$tau_boot,.975)
```

{{< pagebreak >}}

```{r print_table_2_3, echo=FALSE}
tibble(Inferior=quantil_95_izq, Superior=quantil_95_der) %>% 
  kable(digits=3, 
        booktabs=T) %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
```

-   Ahora volvamos a inferencia bayesiana, calcula un intervalo de confianza para $\tau$ y un histograma de la distribución posterior de $\tau$.

**Respuesta:** Dado que en Baysesiana trabajamos una vez con los datos dados es más fácil agarrar la info y hacer la transformación.

```{r, warning = FALSE}
df_posterior <- 
  df_posterior %>% dplyr::mutate(tau_bayes = log(sqrt(post_samples)))
```

```{r graph_A_B_2_3}
#| echo=FALSE,
#| warning=FALSE,
#| fig.cap="Comparativo Bayesiano vs. Bootstrap (Tau)"

a <- ggplot(df_posterior, aes(x = tau_bayes)) +
  geom_histogram(aes(x = tau_bayes, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = log(sqrt((9848.82/74.05))), 
             color = "red", 
             linetype = "dashed") +
  annotate("text", 
           x = log(sqrt((9848.82/74.05))), 
           y = Inf, 
           label = "2.4452", 
           vjust = 1, 
           hjust = 0.5, 
           colour = "red")+
  labs(title = "Simulaciones de posterior", 
       subtitle = "InvGamma(75.05,9848.82)") + 
  xlab("Tau") + 
  ylab("Densidad") + 
  xlim(0,4)+
  ggpubr::theme_pubclean(base_size = 8)

b <- ggplot(reps_boot, aes(x = tau_boot)) +
  geom_histogram(aes(x = tau_boot, 
                     y = ..density..), 
                 bins = 30, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = 2.44, 
             color = "red", 
             linetype = "dashed") +
  annotate("text", 
           x = 2.44, 
           y = Inf, 
           label = "2.4387", 
           vjust = 1, 
           hjust = 0.5,
           colour = "red")+
  labs(title = "Replicaciones bootstrap", 
       subtitle = "MLE: Tau") + 
  xlab("Tau") + 
  ylab("Densidad") + 
  xlim(0,4)+
  ggpubr::theme_pubclean(base_size = 8)

a+b
```

El intervalo de credibilidad (al 95%) para $\tau$ es:

```{r warning = FALSE, echo=FALSE}
tibble(Inferior=round(log(sqrt(1/qgamma(0.975, alpha_post, beta_post))),3),
       Superior=round(log(sqrt(1/qgamma(0.025, alpha_post, beta_post))),3)) %>% 
  kable(booktabs=T) %>%
  kableExtra::kable_styling(latex_options = c('hold_position'))
       
```

{{< pagebreak >}}

## 3. Bayesiana y regularización

Los datos *pew_research_center_june_elect_wknd_data.dta* tienen información de encuestas realizadas durante la campaña presidencial 2008 de EUA.

```{r, warning=FALSE}
set.seed(156057)
data <- foreign::read.dta("data/pew_research_center_june_elect_wknd_data.dta")
```

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

**NOTA**: para cada respuesta se presenta solo un ejemplo del data.frame, al final como anexo se agrega la tabla para los 48 estados considerados.

A falta de más información se decidió tomar la columna *weight* como factor de expanción para las encuestas por lo que el total de población por estado será la suma de esta columna. Para el total de encuestas se considero que cada registro (renglón) era una, por lo que el total de encuestas es el conteo de registros por estado.

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

-   Estima el porcentaje de la población de cada estado (excluyendo Alaska, Hawai, y DC) que se considera *very liberal*, utilizando el estimador de máxima verosimilitud.

-   Grafica en el eje *x* el número de encuestas para cada estado y en el eje *y* la estimación de máxima verosimilitud para *very liberal*. ¿Qué observas?

**R:** Excluimos los estados mencionados y utilizamos la variable *weight* como factor de expansión para realizar los calculos del porcentaje de *very liberal*. Además cada registro lo tomamos en cuenta como si fuera 1 encuesta, entonces entendemos por número de encuestas como número de registros agrupados por la variable *state*. El estimador de **máxima verosimilitud** para una proporción, *very liberal* como se ha demostrado varias veces en clase y en la pregunta 2 será $\frac{x_{very.liberal}}{n}$

```{r, warning=FALSE}
set.seed(156057)
# Consideramos que la población total de mi estado es la suma de "weight" 
very_liberal <- 
  data %>% 
  # Sin alaska, hawaii, washington dc
  dplyr::filter(!(state %in% c("washington dc","hawaii","alaska"))) %>%
  dplyr::group_by(state, ideo) %>% 
  dplyr::summarise(poblacion = sum(weight),
                   poblacion_fix = n()) %>%
  tidyr::pivot_wider(id_cols = state, names_from = ideo, values_from = poblacion) %>%
  ungroup()

# Población total = suma de weight; # de encuestas = conteo de renglones
poblacion_encuestas <- 
  data %>% 
  # Sin alaska, hawaii, washington dc
  dplyr::filter(!(state %in% c("washington dc","hawaii","alaska"))) %>%
  dplyr::group_by(state) %>% 
  dplyr::summarise(poblacion = sum(weight),
                   encuestas = n()) %>% ungroup()

tabla_aux <- dplyr::left_join(very_liberal, poblacion_encuestas, by = "state")

tabla_aux <- tabla_aux %>%
  dplyr::mutate(perc_very_liberal = round((`very liberal`/poblacion)*100,2))

kable(tabla_aux %>% 
      dplyr::select(state, perc_very_liberal, encuestas) %>% head(),
      caption = "Head por estado con MLE",
      digits = 4,
      format = "latex",
      booktabs = T) %>%
  kable_styling(latex_options = c("striped"),
                bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, fixed_thead = T)
```

Graficamos... Observamos una **ligera relación positiva: a mayor número de encuestas mayor el porcentaje de población que se identifican con la ideología de very liberal**. Esto es de llamar la atención, no deberían de depender nuestros resultados del número de encuestas podría haber problemas con el muestro. Sin embargo, al estar hablando de porcentajes "relativamente bajos" el encuestar podría llegarse a ver esta relación.

```{r, warning=FALSE, fig.cap= "Pct Very Liberal vs. Num. Encuestas (archivo DTA)"}
set.seed(156057)
ggplot(tabla_aux, aes(x = encuestas, y = perc_very_liberal)) + 
  geom_point() +
  geom_text_repel(aes(label = state), box.padding = 0.5, size = 1.5) +
  #geom_text(aes(label = state), hjust = 1.5, vjust = 0.5, size = 1.5) + 
  geom_smooth(method = "lm", se = FALSE, color = "#F8766D", linetype = "dashed") +
  labs(title = "Num. Encuestas vs. Pct Very Liberal") + 
  xlab("Num Encuestas") + ylab("Pct Very Liberal (MLE)") + 
  ylim(0,12) +
  ggpubr::theme_pubclean(base_size = 12)
```

-   Grafica en el eje *x* el porcentaje de votos que obtuvo Obama en la elección para cada estado y en el eje *y* la estimación de máxima verosimilitud para *very liberal*. ¿Qué observas? (usa los datos *2008ElectionResult.csv*)

**R:** Realizamos la unión de basos de datos

```{r, warning=FALSE}
set.seed(156057)
data_xls <- data.table::fread("data/2008ElectionResult.csv") %>%
  dplyr::select(state, vote_Obama_pct)
tabla_aux <- dplyr::mutate(tabla_aux, state = toupper(state))
data_xls <- dplyr::mutate(data_xls, state = toupper(state))

tabla_aux <- left_join(tabla_aux, data_xls, by = "state")

kable(tabla_aux %>% 
      dplyr::select(state, perc_very_liberal, encuestas, vote_Obama_pct) %>%
      head(),
      caption = "Head por estado con MLE + Obama",
      digits = 4,
      format = "latex",
      booktabs = T) %>%
  kable_styling(latex_options = c("striped"),
                bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, fixed_thead = T)
```

Graficamos... Observamos una **ligera relación negativa: a mayor número de votantes de Obama menor el porcentaje de población que se identifica con la ideología de very liberal**. Esto hace sentido ya que Obama en general fue percibido como un candidato de *centro-izquierda* más que alguien que representará la ideología muy liberal

```{r, warning=FALSE, fig.cap = "MLE vs. Pct de votantes por Obama"}
set.seed(156057)
ggplot(tabla_aux, aes(x = vote_Obama_pct, y = perc_very_liberal)) + 
  geom_point() +
  geom_text_repel(aes(label = state), box.padding = 0.5, size = 1.2) + 
  #geom_text(aes(label = state), hjust = 1.5, vjust = 0.5, size = 1.5) + 
  geom_smooth(method = "lm", se = FALSE, color = "#F8766D", linetype = "dashed") +
  labs(title = "Pct Obama vs. Pct Very Liberal") + 
  xlab("Pct Obama") + ylab("Pct Very Liberal (MLE)") + 
  ylim(0,12) +
  ggpubr::theme_pubclean(base_size = 12)
```

-   Estima el mismo porcentaje (*very liberal*) usando inferencia bayesiana, en particular la familia conjugada beta-binomial. Deberás estimar la proporción de manera independiente para cada estado, sin embargo, utilizarás la misma inicial a lo largo de todos: $Beta(8,160)$.

**R:** Al tener un modelo beta-binomial sabemos que la **posterior tendrá una distribución Beta**. Previo a establecer una función general para la posterior realizamos simulaciones de la inicial para ver que información previa tenemos.

$$
p(\theta) \propto \theta^{8-1} (1-\theta)^{160-1}
$$

Como era de esperar tenemos una **media cercana al 5%. No es simétrica ya que considera los posibles escenarios que cubren las colas largas** para porcentajes más altos.

```{r, warning=FALSE, fig.cap = "Distribución a priori: Beta (8,160)"}
set.seed(156057)
sim_inicial <- tibble(theta = stats::rbeta(10000,8,160))
ggplot(sim_inicial) + 
  geom_histogram(aes(x = theta, y = ..density..), bins = 15, 
                 fill = "#F8766D",
                 alpha=0.5) + 
  geom_vline(xintercept = (8/168), color = "red") +
  annotate("text", x = (8/168), y = Inf, label = "Media", 
           vjust = 1, hjust = 0.5,colour = "red")+
  labs(title = "Distribución Inicial", subtitle = "Beta(8,160)") + 
  xlab("Theta") + ylab("Densidad") + 
  ggpubr::theme_pubclean(base_size = 12)
```

La posterior para el *estado i* estará dada por:

$$
\begin{aligned}&P(\theta|X) \propto P(X|\theta)P(\theta) \\&P(\theta|X) \propto \theta^{k_i+7}(1-\theta)^{n_{i}+159} \sim Beta(k_i+8,n_i+160)\\\end{aligned}
$$

Donde:

-   $k_i$: es el número de individuos identificados con la ideología *very liberal*

-   $n_i$: total de la población

Y nuestro estimador puntual será la media posterior, es decir: $\frac{k_i+8}{(k_i+8)+(n_i+160)}$

Dejamos código pero la tabla se muestra hasta el final (El total de estados con sus estimadores)

```{r warning=FALSE}
set.seed(156057)
for (i in 1:nrow(tabla_aux)) {
  alpha <- tabla_aux$`very liberal`[i] + 8
  beta <- tabla_aux$poblacion[i] + 160
  tabla_aux$bayesiano[i] <- round((alpha/(alpha+beta)*100),2)
}


kable(tabla_aux %>% 
      dplyr::select(state, perc_very_liberal, bayesiano, encuestas) %>% 
      head(),
      caption = "Head por estado con estimaciones (+Bayesiano)",
      digits = 4,
      format = "latex",
      booktabs = T) %>%
  kable_styling(latex_options = c("striped"),
                bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, fixed_thead = T)
```

-   Para dos de los estados: Idaho y Virginia, adicional a calcular la posterior usando las propiedades de la familia conjugada, utiliza Stan para hacer la inferencia, revisa los diagnósticos de convergencia y describe tus observaciones ($\hat{R}$ y $ESS$).

**R:** Realizamos estimaciones vía *Stan*. Dado que es la misma inicial un mismo modelo nos funciona para ambos Estados.

```{r, warning=FALSE}
set.seed(156057)
archivo_stan <- file.path("stan/modelo_preg3.stan")
# compilar
mod <- cmdstan_model(archivo_stan)
mod
```

Pasamos datos, muestreamos y revisamos convergencia

**IDAHO**

```{r, warning=FALSE}
n <- dplyr::filter(tabla_aux, state == "IDAHO")$poblacion
y <- dplyr::filter(tabla_aux, state == "IDAHO")$`very liberal`
datos_lista <- list(n = n, y = y)
ajuste <- mod$sample(
  data = datos_lista,
  seed = 156057,
  chains = 4,
  iter_warmup = 5000,
  iter_sampling = 20000,
  parallel_chains = 4,
  show_messages = F)
ajuste$cmdstan_diagnose()
idaho <- ajuste$summary() %>%
  dplyr::mutate(state = "Idaho") %>%
  dplyr::select(state,variable, mean, sd, rhat, ess_bulk, ess_tail)
```

**VIRGINIA**

```{r, warning=FALSE}
n <- dplyr::filter(tabla_aux, state == "VIRGINIA")$poblacion
y <- dplyr::filter(tabla_aux, state == "VIRGINIA")$`very liberal`
datos_lista <- list(n = n, y = y)
ajuste <- mod$sample(
  data = datos_lista,
  seed = 156057,
  chains = 4,
  iter_warmup = 5000,
  iter_sampling = 20000,
  parallel_chains = 4,
  show_messages = F)
ajuste$cmdstan_diagnose()
virginia <- ajuste$summary() %>% 
  dplyr::mutate(state = "Virginia") %>%
  dplyr::select(state,variable, mean, sd, rhat, ess_bulk, ess_tail) 
```

Observamos que el valor de la posterior tiene efectos diferentes entre ambos estados. Para Idaho la media posterior aumenta, pasando de 0.047 a 0.057 y para Virginia disminuye ligeramente de 0.047 a 0.043. Los valores de *rhat* muestran un buen ajuste

```{r, warning=FALSE}
stan_resumen <- rbind(idaho, virginia)
kable(stan_resumen,
      caption = "Estimaciones via Stan para Idaho y Virginia",
      digits = 4,
      format = "latex",
      booktabs = T) %>%
  kable_styling(latex_options = c("striped"),
                bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, fixed_thead = T)
```

-   Utiliza la media posterior de cada estado como estimador puntual y repite las gráficas del inciso anterior.

**R:** Realizamos las mismas gráficas; sin embargo, ahora utilizamos la media posterior como estimadores puntuales.

**La relación encontrada se mantiene respecto a la relación entre número de encuestas y el porcentaje estimado de la población con ideología** *very liberal*

```{r, warning=FALSE, fig.cap = "Bayes-MLE y Num. Encuestas"}
set.seed(156057)
tabla_aux_plot <- 
  tabla_aux %>%
  dplyr::select(state, perc_very_liberal, vote_Obama_pct, bayesiano, encuestas) %>%
  dplyr::rename(MLE=perc_very_liberal) %>%
  tidyr::pivot_longer(
    cols = c(MLE, bayesiano),
    names_to = "Metodologia",
    values_to = "value"
  )
ggplot(tabla_aux_plot, aes(x = encuestas, y = value, color = Metodologia)) + 
  geom_point() +
  geom_text_repel(aes(label = state), box.padding = 0.5, size = 1.5) +
  #geom_text(aes(label = state), hjust = 1.5, vjust = 0.5, size = 1.5) + 
  #geom_smooth(method = "lm", se = FALSE, color = Metodologia) +
  geom_smooth(method = "lm", se = FALSE, 
              aes(group = Metodologia, color = Metodologia), 
              linetype = "dashed") +
  labs(title = "Num. Encuestas vs. Pct Very Liberal", subtitle = "MLE vs. Bayesiano") + 
  xlab("Num. Encuestas") + ylab("Pct Very Liberal") + 
  ylim(0,12) +
  ggpubr::theme_pubclean(base_size = 12)
```

**La relación encontrada se mantiene respecto a la relación entre porcentaje de población votante por Obama y el porcentaje estimado de la población con ideología** *very liberal*. Un factor a considerar es que en esta gráfica es mucho más notorio que la estimación bayesiana en probabilidades bajas obtenidas por MLE son un poco mayores y probabilidades relativamente más altas por MLE ahora son un poco menores.

```{r, warning=FALSE, fig.cap = "Bayes vs. MLE y Pct Obama"}
ggplot(tabla_aux_plot, aes(x = vote_Obama_pct, y = value, color = Metodologia)) + 
  geom_point() +
  geom_text_repel(aes(label = state), box.padding = 0.5, size = 1.5) +
  #geom_text(aes(label = state), hjust = 1.5, vjust = 0.5, size = 1.5) + 
  #geom_smooth(method = "lm", se = FALSE, color = Metodologia) +
  geom_smooth(method = "lm", se = FALSE, 
              aes(group = Metodologia, color = Metodologia), 
              linetype = "dashed") +
  labs(title = "Num Encuestas vs. Pct Very Liberal", subtitle = "MLE vs. Bayesiano") + 
  xlab("Pct Obama") + ylab("Pct Very Liberal") + 
  ylim(0,12) +
  ggpubr::theme_pubclean(base_size = 12)
```

**Apéndice**

Tabla con todas las estimaciones para todos los estados.

```{r warning=FALSE}
kable(tabla_aux %>%
        dplyr::select(state, perc_very_liberal, bayesiano) %>%
        dplyr::rename(MLE = perc_very_liberal, Bayesiano = bayesiano), 
      caption = "Estimaciones por estado",
      digits = 4,
      format = "latex",
      booktabs = T) %>%
  kable_styling(latex_options = c("striped"),
                bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, fixed_thead = T)
```
